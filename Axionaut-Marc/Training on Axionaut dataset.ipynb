{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pXIp1unNuVTA"
   },
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "NCdkReU3ujI5",
    "outputId": "306a10f7-c0f8-44c2-88f8-4aab26a8c93c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-11-22 07:45:49--  https://s3.amazonaws.com/axionautdataset/Datasets+2.zip\n",
      "Résolution de s3.amazonaws.com (s3.amazonaws.com)… 52.216.137.174\n",
      "Connexion à s3.amazonaws.com (s3.amazonaws.com)|52.216.137.174|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 1719750362 (1,6G) [application/zip]\n",
      "Enregistre : «Datasets+2.zip»\n",
      "\n",
      "Datasets+2.zip       14%[=>                  ] 231,68M  2,41MB/s    tps 7m 23s "
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "!wget https://s3.amazonaws.com/axionautdataset/Datasets+2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5nJqwldqurCB",
    "outputId": "5ecb1594-75d9-483a-bcc3-60dae286966a"
   },
   "outputs": [],
   "source": [
    "#!unzip self-driving-toy-car.zip \n",
    "!unzip Datasets+2.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvpckCXuu1q5"
   },
   "source": [
    "# Initialize constants\n",
    "This is hands-on is heavily inspired of this [notebook](https://github.com/Axionable/Axionaut).\n",
    "\n",
    "Here, the behaviour of the car is very simple, and can be greatly improved.\n",
    "The neural network learns the steering between 5 possibilities: hard right, right, straight, left and hard left.\n",
    "\n",
    "No acceleration, no slowing down, only one car on the track. Even if that model is that simple, it was the winner of the second [IronCar France](http://ironcar.org/) robocar competition (in 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3SCiWDOu41m"
   },
   "outputs": [],
   "source": [
    "def label_decoder(line):\n",
    "    '''Returns human-readible label from target array.\n",
    "    \n",
    "    '''\n",
    "    if np.array_equal(line, [1,0,0,0,0]):\n",
    "        return 'hard_right'\n",
    "    elif np.array_equal(line, [0,1,0,0,0]):\n",
    "        return 'soft_right'\n",
    "    elif np.array_equal(line, [0,0,1,0,0]):\n",
    "        return 'straight'\n",
    "    elif np.array_equal(line, [0,0,0,1,0]):\n",
    "        return 'soft_left'\n",
    "    elif np.array_equal(line, [0,0,0,0,1]):\n",
    "        return 'hard_left'\n",
    "    else:\n",
    "        print('Error: Label not recognized.')\n",
    "        return \n",
    "\n",
    "    \n",
    "def label_decoder_int(line):\n",
    "    '''Convert label from array to integer.\n",
    "    \n",
    "    '''\n",
    "    if np.array_equal(line, [1,0,0,0,0]):\n",
    "        return -1\n",
    "    elif np.array_equal(line, [0,1,0,0,0]):\n",
    "        return -0.5\n",
    "    elif np.array_equal(line, [0,0,1,0,0]):\n",
    "        return 0\n",
    "    elif np.array_equal(line, [0,0,0,1,0]):\n",
    "        return 0.5\n",
    "    elif np.array_equal(line, [0,0,0,0,1]):\n",
    "        return 1\n",
    "    else:\n",
    "        print('Error: Label not recognized.')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O_VAgXQ5538n",
    "outputId": "5aa44049-19bb-4bce-c467-b5fe25a0fb53"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load dada from Numpy array\n",
    "X_axio = np.load('Datasets/axionable_data/X_train_axio.npy')\n",
    "Y_axio = np.load('Datasets/axionable_data/Y_train_axio.npy')\n",
    "print('Axionable data Loaded. Shape = ', np.shape(X_axio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NnamKwU02HnK"
   },
   "outputs": [],
   "source": [
    "\n",
    "# New track - Double chicane\n",
    "X_chicane = np.load('Datasets/ironcar_data/new_track/x_chicane.npy')\n",
    "Y_chicane = np.load('Datasets/ironcar_data/new_track/y_chicane.npy')\n",
    "# Old track - Balanced dataset\n",
    "X_iron = np.load('Datasets/ironcar_data/old_track/balanced_iron_X.npy')\n",
    "Y_iron = np.load('Datasets/ironcar_data/old_track/balanced_iron_Y.npy')\n",
    "# New double Chicane\n",
    "X_chicane2 = np.load('Datasets/new/x_chicane.npy')\n",
    "Y_chicane2 = np.load('Datasets/new/y_chicane.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R0U6QCSr2lhg",
    "outputId": "0c423180-4e3d-493b-a94d-b17a8e3e48b2"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Concatenate both augmented datasets in a single one\n",
    "X = np.concatenate((X_axio, X_chicane, X_iron, X_chicane2))\n",
    "Y = np.concatenate((Y_axio, Y_chicane, Y_iron, Y_chicane2))\n",
    "print('Total X shape after augmentation = ', np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "8jYEVDuGAzWa",
    "outputId": "4d5034be-fe40-4d0f-9b98-5456b207b8c3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert targets to a Pandas Data Frame\n",
    "df = pd.DataFrame(Y)\n",
    "\n",
    "# Convert targets to integer (-1 = hard_right, 1 = hard_left)\n",
    "df['direction'] = df.apply(label_decoder_int, axis=1)\n",
    "\n",
    "# Check that the dataset is representative of reality, in order to avoid biases: \n",
    "# most of the cases should be \"going straight forward\", some should be \"right\" or \"left\", fewer should be \"full right\" or \"full left\"\n",
    "df.direction.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hb84YhSavL9h"
   },
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7NyoRe-OvSiY"
   },
   "source": [
    "## Read an image and the corresponding steering angle\n",
    "The data were collected by driving the car manually, with a wifi remote, and saving the commands of the driver.\n",
    "\n",
    "X contains the images watched by the car, Y contains the corresponding commands issued by the driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hrVqDJiJvEei"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def read_image_and_steering(img_number):\n",
    "  \n",
    "  image = X[img_number]\n",
    "  steer = Y[img_number]\n",
    "  \n",
    "  return image, steer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m11voxFRvhUJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def draw_steer(image, steer, color):\n",
    "    center = (image.shape[1]//2, image.shape[0]//2)\n",
    "    offset = (image.shape[1]//2 + int(-label_decoder_int(steer)*image.shape[1]/2), image.shape[0]//2)\n",
    "    \n",
    "    img = image.copy()\n",
    "    cv2.arrowedLine(img, center, offset, color=color, thickness=1, tipLength=0.4)      \n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "vQeRuwjUvnGg",
    "outputId": "4132c5a3-31b6-4635-b1b1-a552dc63a007"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "img_test, steer_test = read_image_and_steering(random.randint(0, X_axio.shape[0]))\n",
    "\n",
    "print(steer_test)\n",
    "img_test_with_steer = draw_steer(img_test, steer_test, (255, 0, 0))\n",
    "plt.imshow(img_test_with_steer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XLzDsAirv-qD"
   },
   "source": [
    "##Augment the dataset\n",
    "As usual, we add random transformations to the images, so that the neural network would learn to drive in different conditions: dark, light, shadows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ODCOQjtBACY7"
   },
   "outputs": [],
   "source": [
    "\n",
    "def horizontal_flip(img, steer):\n",
    "    \"\"\"Horizontal image flipping and angle correction.\n",
    "    Img: Input image to transform in Numpy array.\n",
    "    Angle: Corresponding label. Must be a 5-elements Numpy Array.\n",
    "    \"\"\"    \n",
    "    return np.fliplr(img), np.flipud(steer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "B7zKc7vqAFFT",
    "outputId": "25aee271-3b35-4a9e-a663-738c245383b5"
   },
   "outputs": [],
   "source": [
    "img_test_flip, steer_test_flip = horizontal_flip(img_test, steer_test)\n",
    "img_test_flip_with_steer = draw_steer(img_test_flip, steer_test_flip, (255, 0, 0))\n",
    "plt.imshow(img_test_flip_with_steer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lc4Eshj1CRuv"
   },
   "outputs": [],
   "source": [
    "\n",
    "def augment_brightness_camera_images(image):\n",
    "    '''Random bright augmentation (both darker and brighter).\n",
    "    \n",
    "    Returns:\n",
    "    Transformed image and label.\n",
    "    '''\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    image1 = np.array(image1, dtype = np.float64)\n",
    "    random_bright = .5+np.random.uniform()\n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1[:,:,2][image1[:,:,2]>255]  = 255\n",
    "    image1 = np.array(image1, dtype = np.uint8)\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "swaF-Y4ACWrH",
    "outputId": "1567db62-6f86-4395-bf95-ff93e14d3b15"
   },
   "outputs": [],
   "source": [
    "img_test_bright = augment_brightness_camera_images(img_test)\n",
    "img_test_bright_with_steer = draw_steer(img_test_bright, steer_test, (255, 0, 0))\n",
    "plt.imshow(img_test_bright_with_steer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HwP0mPWismjr"
   },
   "outputs": [],
   "source": [
    "\n",
    "def add_random_shadow(image):\n",
    "    '''Add random dark shadows to a given image.\n",
    "    Returns:\n",
    "    Transformed image and label.\n",
    "    '''\n",
    "    top_y = 320*np.random.uniform()\n",
    "    top_x = 0\n",
    "    bot_x = 160\n",
    "    bot_y = 320*np.random.uniform()\n",
    "    image_hls = cv2.cvtColor(image,cv2.COLOR_RGB2HLS)\n",
    "    shadow_mask = 0*image_hls[:,:,1]\n",
    "    X_m = np.mgrid[0:image.shape[0],0:image.shape[1]][0]\n",
    "    Y_m = np.mgrid[0:image.shape[0],0:image.shape[1]][1]\n",
    "    shadow_mask[((X_m-top_x)*(bot_y-top_y) -(bot_x - top_x)*(Y_m-top_y) >=0)]=1\n",
    "    #random_bright = .25+.7*np.random.uniform()\n",
    "    if np.random.randint(2)==1:\n",
    "        random_bright = .5\n",
    "        cond1 = shadow_mask==1\n",
    "        cond0 = shadow_mask==0\n",
    "        if np.random.randint(2)==1:\n",
    "            image_hls[:,:,1][cond1] = image_hls[:,:,1][cond1]*random_bright\n",
    "        else:\n",
    "            image_hls[:,:,1][cond0] = image_hls[:,:,1][cond0]*random_bright    \n",
    "    image = cv2.cvtColor(image_hls,cv2.COLOR_HLS2RGB)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "11aqKRgvspT8",
    "outputId": "cab7b2d0-2788-4c1e-b854-05e92e5bd8a9"
   },
   "outputs": [],
   "source": [
    "img_test_shadow = add_random_shadow(img_test)\n",
    "img_test_shadow_with_steer = draw_steer(img_test_shadow, steer_test, (255, 0, 0))\n",
    "plt.imshow(img_test_shadow_with_steer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_hIA5Gas1fr"
   },
   "outputs": [],
   "source": [
    "\n",
    "import skimage.exposure as exposure\n",
    "\n",
    "def night_effect(img, vmin=185, vmax=195):\n",
    "    \"\"\"Change road color to black simulating night road.\n",
    "    Returns\n",
    "    Transformed image and label.\n",
    "    \"\"\"\n",
    "    limit = random.uniform(vmin,vmax)\n",
    "    low_limit = 146 \n",
    "    int_img = exposure.rescale_intensity(img, in_range=(low_limit,limit), out_range='dtype')\n",
    "    \n",
    "    return int_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "pEV490rQs5qt",
    "outputId": "6f32104e-45a7-4093-d497-f6bfea616445"
   },
   "outputs": [],
   "source": [
    "\n",
    "img_test_night = night_effect(img_test)\n",
    "img_test_night_with_steer = draw_steer(img_test_night, steer_test, (255, 0, 0))\n",
    "plt.imshow(img_test_night_with_steer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cb3P8azatwFY"
   },
   "outputs": [],
   "source": [
    "\n",
    "def adjust_gamma_dark(image, min_=0.7, max_=0.8):\n",
    "    '''Gamma correction to generate darker images.\n",
    "    Image: Image in Numpy format (90,250,3)\n",
    "    Label: Corresponding label of the image.\n",
    "    Min: Minimum gamma value (the lower the darker)\n",
    "    Max: Maximum gamma value (the higher the brigther) \n",
    "    Return:\n",
    "    Transformed image and label.\n",
    "    '''\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    gamma = random.uniform(min_,max_)\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "colab_type": "code",
    "id": "X2TOvPFytxiZ",
    "outputId": "5ac153fe-c816-4a18-cd8f-df314561ede5"
   },
   "outputs": [],
   "source": [
    "\n",
    "img_test_dark = adjust_gamma_dark(img_test)\n",
    "img_test_dark_with_steer = draw_steer(img_test_dark, steer_test, (255, 0, 0))\n",
    "plt.imshow(img_test_dark_with_steer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "404MfvpEwPrM"
   },
   "outputs": [],
   "source": [
    "\n",
    "def augment(image, steer):\n",
    "    \n",
    "    if np.random.random() > 0.75:\n",
    "        image = adjust_gamma_dark(image)\n",
    "    elif np.random.random() > 0.75:\n",
    "        image = night_effect(image)\n",
    "    elif np.random.random() > 0.75:\n",
    "        image = add_random_shadow(image)\n",
    "    elif np.random.random() > 0.75:\n",
    "        image = augment_brightness_camera_images(image)\n",
    "    elif np.random.random() > 0.75:\n",
    "        image = augment_brightness_camera_images(image)\n",
    "        image =  add_random_shadow(image)\n",
    "        image, steer = horizontal_flip(image, steer)\n",
    "                \n",
    "    return image, steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "SF50YRskwcwP",
    "outputId": "cc1ba36c-edb1-4ba5-fd10-41624b2780e2"
   },
   "outputs": [],
   "source": [
    "img_test_augmented, steer_augmented = augment(img_test, steer_test)\n",
    "print(steer_augmented)\n",
    "img_test_augmented_with_steer = draw_steer(img_test_augmented, steer_augmented, (255, 0, 0))\n",
    "plt.imshow(img_test_augmented_with_steer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c9LJg29XxCLw"
   },
   "source": [
    "##Create a generator for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FfMcE_sixHxv"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from itertools import islice\n",
    "\n",
    "def batch_generator(imgs, batch_size):\n",
    "    \"\"\"\n",
    "    Implement batch generator that yields items in batches of size batch_size.\n",
    "    There's no need to shuffle input items, just chop them into batches.\n",
    "    Remember about the last batch that can be smaller than batch_size!\n",
    "    Input: any iterable (list, generator, ...). You should do `for item in items: ...`\n",
    "        In case of generator you can pass through your items only once!\n",
    "    Output: In output yield each batch as a list of items.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    # https://stackoverflow.com/questions/24527006/split-a-generator-into-chunks-without-pre-walking-it\n",
    "    iterator = iter(imgs)\n",
    "    for first in iterator:        \n",
    "        yield list(chain([first], islice(iterator, batch_size - 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GUkPC7JExLsc"
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalize(image):\n",
    "    '''Return image centered around 0 with +- 0.5.\n",
    "    image: Image to transform in Numpy array.\n",
    "    '''\n",
    "    return image/255.-.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOP0_esyxOwh"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_generator(imgs_numbers, batch_size, shuffle = True, jitter = True, norm=True):\n",
    "  \n",
    "    if shuffle: np.random.shuffle(imgs_numbers)\n",
    "      \n",
    "    while True:  # so that Keras can loop through this as long as it wants\n",
    "        for batch in batch_generator(imgs_numbers, batch_size):\n",
    "          \n",
    "            # prepare batch images\n",
    "            batch_imgs = []\n",
    "            batch_targets = []\n",
    "            for img_num in batch:\n",
    "              \n",
    "                image, steer = read_image_and_steering(img_num)\n",
    "                \n",
    "                if jitter: image, steer = augment(image, steer)\n",
    "                if norm:   image = normalize(image)\n",
    "                  \n",
    "                batch_imgs.append(image)\n",
    "                batch_targets.append(steer)\n",
    "            # stack images into 4D tensor [batch_size, img_size, img_size, 3]\n",
    "            batch_imgs = np.stack(batch_imgs, axis=0)\n",
    "            # convert targets into 2D tensor [batch_size, num_classes]\n",
    "            batch_targets = np.stack(batch_targets, axis=0)\n",
    "            yield batch_imgs, batch_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "colab_type": "code",
    "id": "DudckzUgxX-3",
    "outputId": "cb1c9bfb-0f49-4b91-80fe-dc9969eccd39"
   },
   "outputs": [],
   "source": [
    "\n",
    "# test training generator\n",
    "NB_IMGS_TEST = 3\n",
    "\n",
    "img_numbers = np.random.choice(len(X), size=NB_IMGS_TEST)\n",
    "for imgs, steers in train_generator(img_numbers, NB_IMGS_TEST, norm=False):\n",
    "    for img, steer in zip(imgs, steers):\n",
    "      img = draw_steer(img, steer, (255, 0, 0))\n",
    "      plt.imshow(img)\n",
    "      plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wuKl5VDGxsPG"
   },
   "source": [
    "# Construct the neural network\n",
    "The proposed architecture is a slightly modified version of the PilotNet published by [Nvidia](https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf). This architecture is powerful to modelize all possible driving situations while simple enough to run on the raspberry pi 3 B+. Dropout of 10% was added on two classifier layers to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jx2XxZ7O5_A9",
    "outputId": "8f2a45b3-384a-4bb1-f086-fd00f9da2161"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = X.shape[1:]\n",
    "IMG_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKSIPjLPxu4X"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Conv2D\n",
    "from keras.models import Model\n",
    "\n",
    "def model_categorical(input_size= IMG_SIZE, dropout=0.1):\n",
    "    '''Generate an NVIDIA AutoPilot architecture.\n",
    "    Input_size: Image shape (90, 250, 3), adjust to your desired input.\n",
    "    Dropout: Proportion of dropout used to avoid model overfitting.\n",
    "    This model ONLY predicts steering angle as a 5-elements array encoded with a Softmax output.\n",
    "    The model is already compiled and ready to be trained.\n",
    "    '''\n",
    "\n",
    "    \n",
    "    img_in = Input(shape=input_size, name='img_in')                      # First layer, input layer, Shape comes from camera.py resolution, RGB\n",
    "    x = Conv2D(filters=24, kernel_size=(5,5), strides=(2,2), activation='relu')(img_in)       # 24 features, 5 pixel x 5 pixel kernel (convolution, feauture) window, 2wx2h stride, relu activation\n",
    "    x = Conv2D(filters=32, kernel_size=(5,5), strides=(2,2), activation='relu')(x)       # 32 features, 5px5p kernel window, 2wx2h stride, relu activatiion\n",
    "    x = Conv2D(filters=64, kernel_size=(5,5), strides=(2,2), activation='relu')(x)       # 64 features, 5px5p kernal window, 2wx2h stride, relu\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu')(x)       # 64 features, 3px3p kernal window, 2wx2h stride, relu\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), activation='relu')(x)       # 64 features, 3px3p kernal window, 1wx1h stride, relu\n",
    "\n",
    "    # Possibly add MaxPooling (will make it less sensitive to position in image).  Camera angle fixed, so may not to be needed\n",
    "\n",
    "    x = Flatten(name='flattened')(x)                                        # Flatten to 1D (Fully connected)\n",
    "    x = Dense(100, activation='relu')(x)                                    # Classify the data into 100 features, make all negatives 0\n",
    "    x = Dropout(dropout)(x)                                                      # Randomly drop out (turn off) 10% of the neurons (Prevent overfitting)\n",
    "    x = Dense(50, activation='relu')(x)                                     # Classify the data into 50 features, make all negatives 0\n",
    "    x = Dropout(dropout)(x)                                                      # Randomly drop out 10% of the neurons (Prevent overfitting)\n",
    "    \n",
    "    #categorical output of the angle\n",
    "    angle_out = Dense(5, activation='softmax', name='angle_out')(x)        # Connect every input with every output and output 15 hidden units. Use Softmax to give percentage. 15 categories and find best one based off percentage 0.0-1.0\n",
    "    \n",
    "    model = Model(inputs=[img_in], outputs=[angle_out])\n",
    "    \n",
    "    return model\n",
    "  \n",
    "model = model_categorical()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "V8NeJiquyHLO",
    "outputId": "a3bfbb04-e5bd-40fd-eb6c-c8d372b1cc0d"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-b-EJR4EyLBA"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stop  = EarlyStopping(monitor='val_loss', min_delta=0.0005, patience=5, mode='auto', verbose=1)\n",
    "checkpoint  = ModelCheckpoint('weights.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MMrcZXryalY"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# batch generator\n",
    "BATCH_SIZE = 32\n",
    "#BATCH_SIZE = 16\n",
    "\n",
    "imgs_num_train, imgs_num_test = train_test_split(list(range(len(X))), test_size=0.15)\n",
    "\n",
    "num_train = len(imgs_num_train)//BATCH_SIZE\n",
    "num_valid = len(imgs_num_test)//BATCH_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "eK6Vm87wyb5N",
    "outputId": "95e596c5-c28b-4532-8d03-9c4f99c8d852"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(generator = train_generator(imgs_num_train, BATCH_SIZE),\n",
    "                    steps_per_epoch = num_train, \n",
    "                    epochs  = 6, \n",
    "                    verbose = 1,\n",
    "                    validation_data = train_generator(imgs_num_test, BATCH_SIZE, jitter = False), \n",
    "                    validation_steps = num_valid, \n",
    "                    callbacks = [early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MLV5klaHyi7l"
   },
   "source": [
    "# Check the predictions of the steering angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "iTCgS2SCymXj",
    "outputId": "2657d809-0c0c-4d27-ddbd-c95666a282a3"
   },
   "outputs": [],
   "source": [
    "\n",
    "img_test, steer_test = read_image_and_steering(random.choice(imgs_num_test))\n",
    "\n",
    "print(steer_test)\n",
    "img_test = draw_steer(img_test, steer_test, (255, 0, 0))\n",
    "plt.imshow(img_test)\n",
    "\n",
    "steer_pred = model.predict(np.expand_dims(normalize(img_test), axis=0))\n",
    "print(steer_pred)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL - hands-on 4 - Explaining steering angle of autonomous car - Correction.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
